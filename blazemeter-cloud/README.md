# Blazemeter Cloud Trial Image

The [Blazemeter Cloud](https://www.blazemeter.com/) trial job enables you to use Blazemeter performance tests in your Optimize Pro experiments. It leverages a custom container image, based on the the official Blazemeter Taurus([https://](https://gettaurus.org/) [image](https://hub.docker.com/r/blazemeter/taurus/).

Please note that, while this trial job does utilize Blazemeter Taurus, it only officially supports cloud provisioned test execution using BlazeMeter Cloud. 
None of the local executors provided by Taurus are officially supported with this trial job at this time.

## Usage

- Create a BlazeMeter API key, noting both the the key ID and the secret. These will only be shown once.
- Configure the environment variables shown in the next section for your trial job in your `experiment.yaml`
- Configure Trial to use either `prometheus` setupTask or manually define `PUSHGATEWAY_URL`.

## Configuration

| Environment Variable | Description | Default |
| -------------------- | ----------- | ------- |
| `BLAZEMETER_API_ID`        | BlazeMeter cloud API key ID | |
| `BLAZEMETER_API_SECRET`    | BlazeMeter cloud API key secret | |
| `BLAZEMETER_TEST_URL`      | BlazeMeter cloud test URL (e.g. `https://a.blazemeter.com/app/#/accounts/1234567/workspaces/1234567/projects/1234567/tests/12345678`)| |

## Metrics

Metrics are extracted from the summary CSV file generated by the Taurus [final stats reporter](https://gettaurus.org/docs/Reporting/#Final-Stats-Reporter).
This file contains calculated statistics based on all requests executed in the test plan.

| Name | Example Value | Description |
| ---- | ------------- | ---- |
| `concurrency` | - | average number of Virtual Users |
| `throughput` | - | total count of all samples |
| `succ` | - | total count of not-failed samples |
| `fail` | _ | total count of saved samples |
| `avg\_rt` | - | average response time |
| `stdev\_rt` | - | standard deviation of response time |
| `avg\_ct` | - | average connect time if present |
| `avg\_lt` | - |- average latency if present |
| `rc\_200` | - | counts for specific response codes |
| `perc_90` | - | |
| `perc_95` | - | |
| `perc_99` | - | percentile levels for response time, 0 is also minimum response time, 100 is maximum |
| `bytes` | - | total download size |

## Example Kubernetes Manifest

The following Kubernetes Job manifest illustrates how you might leverage this trial job container.

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: sandbox-1
spec:
  backoffLimit: 0
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: black-friday
        image: thestormforge/optimize-trials:latest-jmeter
        env:
        - name: PUSHGATEWAY_URL
          value: http://pushgateway:9091/metrics/job/trialRun/instance/sandbox-1
        volumeMounts:
        - mountPath: /test
          name: jmeter-test-case-file
          readOnly: true
      volumes:
      - name: jmeter-test-case-file
        configMap:
          name: jmeter-test-case
```

NOTE: If you are using this in an experiment, keep in mind that some values are set automatically. In particular, the `backoffLimit`, `restartPolicy`, and `PUSHGATEWAY_URL` environment variable are all introduced when evaluating a trial's job template.
PUSHGATEWAY_URL requires the use of the `prometheus` setupTask.
